{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84ccf55-5636-4898-adc6-8dc694f26ddb",
   "metadata": {},
   "source": [
    "## Q1. What is Bayes' theorem?\n",
    "\n",
    "Bayes' theorem is a fundamental theorem in probability theory that describes the probability of an event based on prior knowledge of conditions that might be related to the event. It allows for the updating of probability estimates as more evidence or information becomes available.\n",
    "\n",
    "## Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "where:\n",
    "- \\( P(A|B) \\) is the posterior probability: the probability of event A given that event B has occurred.\n",
    "- \\( P(B|A) \\) is the likelihood: the probability of event B given that event A has occurred.\n",
    "- \\( P(A) \\) is the prior probability: the initial probability of event A.\n",
    "- \\( P(B) \\) is the marginal probability: the total probability of event B occurring.\n",
    "\n",
    "## Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Bayes' theorem is used in various fields for making probabilistic inferences and decisions. Some practical applications include:\n",
    "- Medical diagnosis: Updating the probability of a disease based on test results.\n",
    "- Spam filtering: Calculating the probability that an email is spam based on its contents.\n",
    "- Machine learning: Used in algorithms like Naive Bayes classifiers for classification tasks.\n",
    "- Risk assessment: Evaluating risks in financial and insurance industries based on historical data.\n",
    "\n",
    "## Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Bayes' theorem is fundamentally based on the concept of conditional probability. It provides a way to reverse conditional probabilities. Specifically, it allows one to calculate the probability of an event \\(A\\) given another event \\(B\\), by using the known conditional probability of \\(B\\) given \\(A\\) and the marginal probabilities of both \\(A\\) and \\(B\\).\n",
    "\n",
    "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Choosing the type of Naive Bayes classifier depends on the nature of the data:\n",
    "- *Gaussian Naive Bayes*: Used when the features are continuous and are assumed to follow a normal distribution.\n",
    "- *Multinomial Naive Bayes*: Suitable for discrete data, often used in text classification where data represent word counts or frequencies.\n",
    "- *Bernoulli Naive Bayes*: Used for binary/boolean features, such as in binary text classification where the presence or absence of words is considered.\n",
    "\n",
    "## Q6. Assignment:\n",
    "\n",
    "Given the dataset, we need to use the Naive Bayes classifier to classify a new instance with features \\( X1 = 3 \\) and \\( X2 = 4 \\). The table provides the frequency of each feature value for each class:\n",
    "\n",
    "\\[ \\begin{array}{cccccc}\n",
    "\\text{Class} & \\text{X1=1} & \\text{X1=2} & \\text{X1=3} & \\text{X2=1} & \\text{X2=2} & \\text{X2=3} & \\text{X2=4} \\\\\n",
    "\\text{A} & 3 & 3 & 4 & 4 & 3 & 3 & 3 \\\\\n",
    "\\text{B} & 2 & 2 & 1 & 2 & 2 & 2 & 3 \\\\\n",
    "\\end{array} \\]\n",
    "\n",
    "Assuming equal prior probabilities for each class:\n",
    "\n",
    "1. *Calculate the likelihood for Class A and Class B*:\n",
    "\n",
    "   For Class A:\n",
    "   - \\( P(X1=3 | A) = \\frac{4}{10} = 0.4 \\)\n",
    "   - \\( P(X2=4 | A) = \\frac{3}{10} = 0.3 \\)\n",
    "\n",
    "   For Class B:\n",
    "   - \\( P(X1=3 | B) = \\frac{1}{9} \\approx 0.111 \\)\n",
    "   - \\( P(X2=4 | B) = \\frac{3}{9} = 0.333 \\)\n",
    "\n",
    "2. *Compute the posterior probabilities (ignoring the constant denominator since the prior probabilities are equal)*:\n",
    "\n",
    "   For Class A:\n",
    "   \\[ P(A|X1=3, X2=4) \\propto P(X1=3|A) \\cdot P(X2=4|A) \\cdot P(A) \\]\n",
    "   \\[ \\propto 0.4 \\cdot 0.3 = 0.12 \\]\n",
    "\n",
    "   For Class B:\n",
    "   \\[ P(B|X1=3, X2=4) \\propto P(X1=3|B) \\cdot P(X2=4|B) \\cdot P(B) \\]\n",
    "   \\[ \\propto 0.111 \\cdot 0.333 \\approx 0.037 \\]\n",
    "\n",
    "3. *Compare the probabilities*:\n",
    "   Since \\( 0.12 > 0.037 \\), the Naive Bayes classifier would predict the new instance with features \\( X1 = 3 \\) and \\( X2 = 4 \\) to belong to *Class A*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a990d-4187-4e9b-84bd-a3be1fce56f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
